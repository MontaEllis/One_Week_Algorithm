### 初级算法梳理

#### 1 线性回归算法梳理
[2019.2.27 ~ 2019.3.1]

学习内容 :
##### 1. 机器学习的一些概念 
* **有监督**
给学习算法一个数据集，通过回归等方法推测出一个连续的结果
* **无监督**
对无标签的数据集进行分析，得到不同的聚集
* **泛化能力**
一种机器学习算法在新的样本上的表现能力
* **过拟合**
算法非常适合训练集，但是过于复杂导致泛化能力变差，在测试集上表现很差
* **欠拟合**
模型过于简单，拟合能力差
* **方差和偏差以及各自解决办法**
偏差是欠拟合
方差是过拟合
解决高偏差方法：
   1. 尝试更多特征
   2. 增加多项式特征
   3. 减少正则化程度$\lambda$

   解决高方差方法：
   1. 更多样本
   2. 减少特征数量
   3. 增加正则化程度$\lambda$
* **交叉验证**
数据622分，6分训练集，2分验证集，2分测试集，可以交叉使用
##### 2. 线性回归的原理
对于一个数据集，构建一个线性模型来预测输出，使得代价函数最小
##### 3. 线性回归损失函数、代价函数、目标函数
* **损失函数**
表示预测值和真实值之间的差异程度
* **代价函数**
$\boldsymbol J(\theta_0,\theta_1)=\frac{1}{2m}\sum^{m}_{i=0}(h_{\theta}(x^{(i)})-y^{(i)})^2$
* **目标函数**
代价函数+正则化
##### 4. 优化方法(梯度下降法、牛顿法、拟牛顿法等)
* **梯度下降法**
沿梯度下降的方向求解极小值
* **牛顿法**
使用泰勒级数的前面几项来寻找方程的根
* **拟牛顿法**
改善牛顿法每次都要求解复杂的Hessian矩阵的逆矩阵的缺陷，使用正定矩阵来近似Hessian矩阵的逆
##### 5、线性回归的评估指标 
MSE,
RMSE
MAE
R Squared
##### 6、sklearn参数详解
使用sklearn.linear_model.LinearRegression
如：clf = LinearRegression()
参数：
1. fit_intercept 是否存在截距，默认存在
2. normalize 标准化开关，默认关闭
3. fit(X,y,sample_weight=None) X,y以矩阵的方式传入
4. predict(X) 预测方法，将返回预测值y_pred
5. score(X,y,sample_weight=None) 评分函数，将返回一个小于1的得分，可能会小于0




